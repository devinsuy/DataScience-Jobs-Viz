# -*- coding: utf-8 -*-
"""eda_job_descriptions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mVMiVKWu8wwBbb8j-JR7m-9rbWJhzoEY
"""

import numpy as np
import pandas as pd
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

df = pd.read_csv('../../../../data/Data_Science_Listings/Data_Scientist_Job_Listings_Data.csv')
print(df.shape)
for col in df.columns:
  print(col)

df['posting_date'] = pd.to_datetime(df['posting_date'])
df['posting_year'] = df['posting_date'].dt.year
df['posting_year'].value_counts()

df['original_job_description1'] = df['original_job_description1'].astype('str')
print(100*df[df['original_job_description1'].isna()].shape[0]/df.shape[0], "% rows have missing description1.")
print(df['original_job_description1'].sample(1).values[0])

df['original_job_description2'] = df['original_job_description2'].astype('str')
print(100*df[df['original_job_description2'].isna()].shape[0]/df.shape[0], "% rows have missing description1.")
print(df['original_job_description2'].sample(1).values[0])

df['remote_allowed'] = 0

for keyword in ['remote', 'work from home', 'anywhere']:
  df.loc[df['original_job_description1'].str.contains(keyword), 'remote_allowed'] = 1

df.loc[df['original_work_type']=='Remote', 'remote_allowed'] = 1

print(df['remote_allowed'].sum(), df.shape[0])

ax = df.groupby('posting_year')['remote_allowed'].value_counts(normalize=True).mul(100).unstack().plot.bar(stacked=True)
plt.show()

from matplotlib import cm
color = cm.inferno_r(np.linspace(.4, .8, 30))

df['original_job_description1'] = df['original_job_description1'].str.lower()

stopwords = ['data science', 'data scientist', 'epam', 'looking']

for stopword in stopwords:
  df['original_job_description1'] = df['original_job_description1'].str.replace(stopword, "")

comment_words = ''
stopwords = set(STOPWORDS)

# iterate through the csv file
for val in df['original_job_description1']:

    # typecaste each val to string
    val = str(val)

    # split the value
    tokens = val.split()

    # Converts each token into lowercase
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()

    comment_words += " ".join(tokens)+" "

wordcloud = WordCloud(width = 2000, height = 800,
                background_color ='white',
                stopwords = stopwords,
                min_font_size = 7).generate(comment_words)

# plot the WordCloud image
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)

print(f"Word Cloud for Job Descriptions")
plt.show()

def wordcloud_by_column(df = df, column_name = 'remote_allowed', figsize=(10,3)):

  comment_words = ''
  stopwords = set(STOPWORDS)

  vis_data = pd.DataFrame(df[column_name].value_counts().sort_index())
  vis = vis_data.plot.barh(figsize=figsize, color='purple')
  vis.bar_label(vis.containers[0])
  plt.show()

  for x in sorted(df[column_name].drop_duplicates().tolist()):

    # iterate through the csv file
    for val in df[df[column_name]==x]['original_job_description1']:

        # typecaste each val to string
        val = str(val)

        # split the value
        tokens = val.split()

        # Converts each token into lowercase
        for i in range(len(tokens)):
            tokens[i] = tokens[i].lower()

        comment_words += " ".join(tokens)+" "

    wordcloud = WordCloud(width = 2000, height = 800,
                    background_color ='white',
                    stopwords = stopwords,
                    min_font_size = 7).generate(comment_words)

    # plot the WordCloud image
    plt.figure(figsize = (8, 8), facecolor = None)
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.tight_layout(pad = 0)

    print(f"Word Cloud for {column_name} = {x}")
    plt.show()

wordcloud_by_column(df = df, column_name = 'remote_allowed')

wordcloud_by_column(df = df, column_name = 'Country')

ax = df.groupby('Country')['remote_allowed'].value_counts(normalize=True).mul(100).unstack().plot.bar(stacked=True)
plt.show()